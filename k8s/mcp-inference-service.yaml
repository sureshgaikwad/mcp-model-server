# k8s/mcp-inference-service.yaml
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: mcp-deployment-model
  namespace: mcp-ai-models
  labels:
    app: mcp-deployment-model
    model-type: deployment-predictor
  annotations:
    serving.kserve.io/deploymentMode: ModelMesh
    autoscaling.knative.dev/minScale: "1"
    autoscaling.knative.dev/maxScale: "5"
spec:
  predictor:
    model:
      modelFormat:
        name: custom
      storageUri: "pvc://mcp-model-storage"
      resources:
        requests:
          cpu: 500m
          memory: 1Gi
          nvidia.com/gpu: 0
        limits:
          cpu: 2000m
          memory: 4Gi
          nvidia.com/gpu: 0
      env:
      - name: GITHUB_TOKEN
        valueFrom:
          secretKeyRef:
            name: mcp-model-secrets
            key: github-token
      - name: OPENSHIFT_TOKEN
        valueFrom:
          secretKeyRef:
            name: mcp-model-secrets
            key: openshift-token
      - name: OPENSHIFT_SERVER
        valueFrom:
          configMapKeyRef:
            name: mcp-model-config
            key: openshift-server
      - name: MODEL_NAME
        value: "mcp-deployment"
      - name: PYTHONPATH
        value: "/opt/model"
    containers:
    - name: kserve-container
      image: quay.io/your-org/mcp-deployment-model:latest
      ports:
      - containerPort: 8080
        protocol: TCP
      command:
      - python
      - src/predictor.py
      volumeMounts:
      - name: model-storage
        mountPath: /opt/model-data
    volumes:
    - name: model-storage
      persistentVolumeClaim:
        claimName: mcp-model-storage
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mcp-model-storage
  namespace: mcp-ai-models
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: gp3-csi
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mcp-model-config
  namespace: mcp-ai-models
data:
  openshift-server: "https://api.your-aro-cluster.region.aroapp.io:6443"
  model-name: "mcp-deployment"
  log-level: "info"
  max-concurrent-requests: "10"
---
apiVersion: v1
kind: Secret
metadata:
  name: mcp-model-secrets
  namespace: mcp-ai-models
type: Opaque
stringData:
  github-token: "ghp_your_github_token_here"
  openshift-token: "your_openshift_service_account_token"
  openai-api-key: "sk-your_openai_key_for_enhanced_analysis"
